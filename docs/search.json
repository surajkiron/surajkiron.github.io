[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projects",
    "section": "",
    "text": "SCARA Manipulator: Kinematic Control Part II\n\n\n\n\n\n\n\nManipulators\n\n\nControl Systems\n\n\nMATLAB\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2024\n\n\nSuraj Kiron Nair\n\n\n\n\n\n\n  \n\n\n\n\nSCARA Manipulator: Kinematic Control Part I\n\n\n\n\n\n\n\nManipulators\n\n\nControl Systems\n\n\nMATLAB\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2024\n\n\nSuraj Kiron Nair\n\n\n\n\n\n\n  \n\n\n\n\nVision Based Pose and Velocity Estimation\n\n\n\n\n\n\n\nComputer Vision\n\n\nLocalization\n\n\nMATLAB\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2023\n\n\nSuraj Kiron Nair\n\n\n\n\n\n\n  \n\n\n\n\nState Estimation with Extended Kalman Filter\n\n\n\n\n\n\n\nLocalization\n\n\nMATLAB\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2023\n\n\nSuraj Kiron Nair\n\n\n\n\n\n\n  \n\n\n\n\nRace Circuit Line Follower\n\n\n\n\n\n\n\nControl Systems\n\n\nComputer Vision\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2022\n\n\nSuraj Kiron Nair\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2022\n\n\nSuraj K Nair\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first blog post. Welcome!\n\nTo me robotics is a fascinating discipline that combines engineering, computer science, and artificial intelligence. ie its the coolest thing ever. As a member of the Agile Robotics and Perception Lab(ARPL) at NYU I have the opportunity to work with this cutting edge technology.\nI will be using this blog to post about projects I’m working on or even random things I find interesting. I have a lot of plans in store for this summer, so I am writing this blog as a record of everything I’m doing. I’m halfway through my Masters in Mechatronics and Robotics and this blog has been a long time coming.\nI believe that robotics has the power to revolutionize the way we live, work, and interact with the world around us. Through this blog, I wish to share my passion for robotics and record my journey through this vast field.\nSo, buckle up and get ready to embark on a thrilling journey into the realm of robotics. Let’s explore the limitless possibilities and discover the future that robots hold for us all."
  },
  {
    "objectID": "posts/1_Line_ Follower/index.html#background",
    "href": "posts/1_Line_ Follower/index.html#background",
    "title": "Race Circuit Line Follower",
    "section": "Background:",
    "text": "Background:\nThe goal of this project was to perform a PID reactive control capable of following the line painted on a racing circuit. PID control is one of the fundamental concepts of Linear control systems. The Controller continuously calculates an error value as the difference between desired output and the current output and applies a correction based on proportional, integral and derivative terms(denoted by P, I, D respectively). The control signal u[k] for a PID controller can be expressed as follows. \n\nProportional:\nProportional Controller gives an output which is proportional to the current error. The error e[k] is multiplied with a proportional gain(Kp) to get the output. And hence, is 0 if the error is 0.In this case the error is the difference between the center of the image and the centroid of the racing line.\n\n\nIntegral:\nIntegral Controller provides a necessary action to eliminate the offset error which is accumulated by the P Controller.It integrates the error over a period of time until the error value reaches to zero.\n\n\nDerivative:\nDerivative Controller gives an output depending upon the rate of change or error with respect to time. It gives the kick start for the output thereby increasing system response.\nThe integral and dervivative errors are calculated as follows."
  },
  {
    "objectID": "posts/1_Line_ Follower/index.html#tuning-the-pid-controller.",
    "href": "posts/1_Line_ Follower/index.html#tuning-the-pid-controller.",
    "title": "Race Circuit Line Follower",
    "section": "Tuning the PID controller.",
    "text": "Tuning the PID controller.\nFirstly, we must setup the P controller as per Ziegler Nichols method. Keep adjusting the value of the constant, till we get a value where there occurs it has neither unstable oscillations and nor slow response.   \nOnce you get oscillations of constant amplitude you can adjust the derivative gains (Kd). After this the vehicle was much more stable and tracked the line accurately. Finally I modified the Integral gain which I found to have minimal effect on the system. But nonetheless helped to avoid any steady state errors."
  },
  {
    "objectID": "posts/1_Line_ Follower/index.html#results-and-code",
    "href": "posts/1_Line_ Follower/index.html#results-and-code",
    "title": "Race Circuit Line Follower",
    "section": "Results and Code",
    "text": "Results and Code\n\nFinal Code"
  },
  {
    "objectID": "posts/1_Line_ Follower/index.html#learning",
    "href": "posts/1_Line_ Follower/index.html#learning",
    "title": "Race Circuit Line Follower",
    "section": "Learning",
    "text": "Learning\nOne mistake I made was to set the velocity of the car too high. Since the cycle time of the system is only 12Hz the controller could not detect the change in error fast enough. This led to understeer and multiple head on collision with the track walls. It’s always a good idea to start with the minimal speed requirement when programming a controller and increase it once the system is more robust."
  },
  {
    "objectID": "posts/1_Line_ Follower/index.html#references",
    "href": "posts/1_Line_ Follower/index.html#references",
    "title": "Race Circuit Line Follower",
    "section": "References:",
    "text": "References:\nJde Robotics Visual Line Follow What is PID control? MATLAB Discrete time equations for PID control"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a student pursuing my Masters in Mechatronics and Robotics at NYU Tandon.\n\n\nNYU Tandon Institute of Technology | New York  MS Mechatronics and Robotics | Sept 2022 - May 2024\nRamaiah Institute of Technology | Bengaluru | India  BE Mechanical Engineering | Sept 2015 - June 2021\n\n\n\nAgile Robotics and Perception Lab (ARPL) | Research Assistant | Jan 2023 - present \n\nImplemented L1 controller, for my Master’s Project\nWorked on Modalai Voxl2 and Nvidia Orin based quadrotor platforms\nDeveloped C++, ROS/ROS2 packages\nFlight tested quadrotors using Vicon and GPS\nSystem Integration and testing\n\nICER IISc | Research Assistant | June 2021 - May 2022"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "NYU Tandon Institute of Technology | New York  MS Mechatronics and Robotics | Sept 2022 - May 2024\nRamaiah Institute of Technology | Bengaluru | India  BE Mechanical Engineering | Sept 2015 - June 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "",
    "text": "ARPL | Graduate Engineer | Jan 2023 - present\nICER IISc | Research Assistant | June 2021 - May 2022"
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html",
    "href": "posts/4_RLAN_1_EKF/index.html",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "",
    "text": "In this project I use a Extended Kalman Filter to Localize a quadrotor. I use the body frame acceleration and angular velocity from the onboard IMU as your control inputs. The measurement will be given by the pose or velocity from the Vicon. Vicon data is in the following format: \\[ [x, y, z, roll, pitch, yaw, v_x, v_y, v_z, \\omega_x, \\omega_y, \\omega_z]^T \\]\nThe on board processor of the robot collects synchronized camera and IMU data and sends them to the mission computer. At this stage, the camera data should not be used. The sensor data is decoded into standard MATLAB format. Note that since the sensor data is transmitted via wireless network, there may or may not be a sensor packet available during a specific iteration of the control loop. A sensor packet is a struct that contains following fields:\nThe goal is to use an Extended Kalman Filter (EKF) to estimate the position, velocity, and orientation, and sensor biases of an Micro Aerial Vehicle. The Vicon velocity is given in the world frame, whereas the angular rate in the body frame of the robot. Furthermore, I use the body frame acceleration and angular velocity from the on board IMU as the inputs.\nI have implemented 2 versions of the filter. In the first one, the measurement update is given by the position and orientation from vicon, in the second one I use only the velocity from the Vicon.. In both parts, the process model is the same."
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html#assumptions",
    "href": "posts/4_RLAN_1_EKF/index.html#assumptions",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "Assumptions",
    "text": "Assumptions\nWe make the assumption that the noise in the readings obtained from the IMU and Vicon adhere to a normal distribution. Additionally, we can assume the state derivative to be both continuous and differentiable, allowing us to linearize it. Based on these assumptions, we can utilize the EKF algorithm for predicting the state."
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html#the-process-model",
    "href": "posts/4_RLAN_1_EKF/index.html#the-process-model",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "The Process Model: ",
    "text": "The Process Model: \nThe state \\(\\mathbf{X}\\) is given by \\[\\mathbf{X} =\n\\begin{bmatrix}\n\\mathbf{x_1} \\\\\n\\mathbf{x_2} \\\\\n\\mathbf{x_3} \\\\\n\\mathbf{x_4} \\\\\n\\mathbf{x_5}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{p} \\\\\n\\mathbf{q} \\\\\n\\mathbf{\\dot{p}} \\\\\n\\mathbf{b_g} \\\\\n\\mathbf{b_a}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{position} \\\\\n\\mathbf{orientation} \\\\\n\\mathbf{linear \\, velocity} \\\\\n\\mathbf{gyroscope \\, bias} \\\\\n\\mathbf{accelerometer \\, bias}\n\\end{bmatrix}\n\\]\nHere \\(\\mathbf{X} \\in \\mathbf{R}^{15}\\) and \\(\\mathbf{q} = [\\phi, \\theta, \\psi] ^T = [roll, pitch, yaw]^T\\). Using the properties of the distributions we can derive the state transition equations.\nWe already have \\(\\dot{\\mathbf{p}}\\) in the state vector. We can calculate \\(\\dot{\\mathbf{q}}\\) using the angular velocity measured by IMU \\((\\omega_m)\\) which is expressed in body frame. Since the gyroscope noise is additive white noise \\(n_g \\sim \\mathit{N}(0,\\mathit{Q})\\). \\[\n\\omega_m = \\omega + b_g + n_g\n\\] \\[\n\\omega = \\omega_m - b_g - n_g\n\\] \\(G(q)\\) is a transformation that maps the euler angle derivatives \\((\\dot{q} = [\\dot{\\phi}, \\dot{\\theta}, \\dot{\\psi}]^T)\\) to angular velocity expressed in world frame. Where \\(G(\\mathbf{q})^{-1}\\) maps orientation to angular velocity and is given by. See eqn 2.76 here \\[\nG(\\mathbf{q})^{-1} =\n\\begin{bmatrix}\n\\frac{\\cos(z)\\sin(y)}{\\cos(y)} & \\frac{\\sin(z)\\sin(y)}{\\cos(y)} & 1\\\\\n-\\sin(z) & \\cos(z) & 0\\\\\n\\frac{\\cos(z)}{\\cos(y)} & \\frac{\\sin(z)}{\\cos(y)} & 0\n\\end{bmatrix}\n\\] \\[\n(\\omega)_{world} = G(q) \\dot{q}\n\\] Since \\(\\omega\\) is expressed in the body frame it need to be rotated to be expressed with respect to the world using \\(R^w_b\\). \\[R^w_b \\omega = G(q) \\dot{q}\\]\nHence finally we get the euler angle derivatives to be \\[\\dot{q} = G(q)^{-1}R_b^w \\omega\\] \\[\\dot{q} = G(q)^{-1}R_b^w(\\omega_m - b_g - n_g) \\]\nSimilarly for acceleration, since we have additive accelerometer noise. \\(n_a \\sim \\mathit{N}(0,\\mathit{Q})\\) The measured acceleration is given by. \\[a_m = R_b^w(\\ddot{p} - g) + b_a + n_a \\]\nand let \\(\\dot{b_g} = n_{bg}\\) and \\(\\dot{b_a} = n_{ba}\\) be gyroscope noise and accelerometer white noise respectively.\nDifferentiating we get the state transition equation as \\[\n\\mathbf{\\dot{X}}=\n\\begin{bmatrix}\n\\mathbf{\\dot{p}} \\\\\n\\mathbf{\\dot{q}} \\\\\n\\mathbf{\\ddot{p }} \\\\\n\\mathbf{\\dot{b_g}} \\\\\n\\mathbf{\\dot{b_a}}\n\\end{bmatrix} =\n\\begin{bmatrix}\n\\mathbf{x_3} \\\\\nG(\\mathbf{q})^{-1}R_b^w (\\mathbf{\\omega_m} - \\mathbf{b_g} - \\mathbf{n_g})\\\\\n\\mathbf{g}+R_b^w(\\mathbf{a_m}-\\mathbf{b_a}-\\mathbf{n_a}) \\\\\n\\mathbf{n_{bg}} \\\\\n\\mathbf{n_{ba}}\n\\end{bmatrix}\n=\nf(\\mathbf{X}, \\mathbf{u}, \\mathbf{n})\n\\]"
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html#prediction-step",
    "href": "posts/4_RLAN_1_EKF/index.html#prediction-step",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "Prediction Step:",
    "text": "Prediction Step:\n\n\n\nPrediction Equations\n\n\nWe use MATLAB symbolic library to determine \\(A_t\\) and \\(U_t\\). \\(Q_d\\) is the covariance of the IMU noise. In the prediction stage, the filter uses the system model to make a prediction of the next state of the system based on the current state and any control inputs from the IMU"
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html#update-step",
    "href": "posts/4_RLAN_1_EKF/index.html#update-step",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "Update Step:",
    "text": "Update Step:\nThe prediction is used to estimate the measurement that will be obtained at the next time step. During the correction stage, the filter incorporates both the predicted measurement and the actual measurement taken at the following time step to refine its assessment of the system’s state. The refined estimate is a weighted sum of the predicted state and the actual measurement, with the filter’s assessment of the uncertainty in both the model and the measurements used to determine the weighting of each component using the Kalman Gain.\n\n\n\nUpdate Equations\n\n\nHere the observation model \\(\\mathbf{z}\\) is given by \\[\n\\mathbf{z}=\n\\begin{bmatrix}\n\\mathbf{p} \\\\\n\\mathbf{q} \\\\\n\\mathbf{r}\n\\end{bmatrix}\n+\n\\mathbf{v}\n=\n\\mathbf{C_t X}+\\mathbf{v}\n\\]\nWhere \\(C_t\\) is a selection matrix. For case 1 we select position and orientation \\[\nC_t =\n\\begin{bmatrix}\nI & 0 & 0 & 0 & 0 & 0\\\\\n0 & I & 0 & 0 & 0 & 0\n\\end{bmatrix}\n\\]\nFor case 2 we select Linear velocitiy \\[\nC_t =\n\\begin{bmatrix}\n0 & 0 & I & 0 & 0 & 0\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/4_RLAN_1_EKF/index.html#results",
    "href": "posts/4_RLAN_1_EKF/index.html#results",
    "title": "State Estimation with Extended Kalman Filter",
    "section": "Results",
    "text": "Results\nI have compared both implementations of the Extended Kalman filter on 3 datasets. 3 being the most agressive flight.\n\nCase 1 Dataset 1\n\n\n\nState Estimation Dataset 1\n\n\n\n\nCase 1 Dataset 2\n\n\n\nState Estimation Dataset 2\n\n\n\n\nCase 1 Dataset 3\n\n\n\nState Estimation Dataset 3\n\n\n\n\nCase 2 Dataset 1\n\n\n\nState Estimation Dataset 1\n\n\n\n\nCase 2 Dataset 2\n\n\n\nState Estimation Dataset 2: shows yaw drift\n\n\n\n\nCase 2 Dataset 3\n\n\n\nState Estimation Dataset 3: shows yaw drift\n\n\nThe results show that the yaw estimate of the quadrotor drifts if we use only velocity measurements to update the EKF. Measuring pose gives us better tracking performance.\nNext Project: Vision Based Pose and Velocity Estimation"
  },
  {
    "objectID": "posts/5_RLAN_2_VO/index.html",
    "href": "posts/5_RLAN_2_VO/index.html",
    "title": "Vision Based Pose and Velocity Estimation",
    "section": "",
    "text": "This project is composed of 2 parts. In part one we have to determine the position and orientation of a quadrotor flying over a Mat of April Tags. For the second part, I estimate the linear and angular velocity of the drone using Optical Flow.\nThe data for this project was collected using a Nano+ quadrotor that was either held by hand or flown through a prescribed trajectory over a mat of AprilTags, each of which has a unique ID.Thes images captured by the quadrotor are in a time sequence. We know the coordinates of each point on the April Tag mat. Using this information we can find the position and orientation of the quadrotor in the world frame.\nThe intrinsic camera calibration matrix and the transformation between the camera and the robot center are known. These Two photos are included to visualize the camera-robot body transform\n\n\n\n\n\n\n\n(a) Side View\n\n\n\n\n\n\n\n(b) Top View\n\n\n\n\nFigure 1: Camera to Body transformation\n\n\nThe data contains a struct array of image data called data, which holds all of the data necessary to do pose estimation. This includes the time stamps, April Tag IDs observed for each time stamp and the location of the April Tag corners and centers in image coordinates.\nThis is a rectified image of the April Tag Mat.\n\n\n\nApril Tag Mat"
  },
  {
    "objectID": "posts/5_RLAN_2_VO/index.html#part-i-pose-estimation",
    "href": "posts/5_RLAN_2_VO/index.html#part-i-pose-estimation",
    "title": "Vision Based Pose and Velocity Estimation",
    "section": "Part I: Pose Estimation",
    "text": "Part I: Pose Estimation\n\nMethodology\nThe goal of this section is to use this data to determine the pose of the quadrotor. I have to use the points of the corners of each AprilTag along with their corresponding positions in the image to estimate the pose of the camera, and then the drone body. I do this by computing the homography matrix H for the points whose position we know in both the image plane as well as the real-world. The homography matrix converts points in the 3D world frame to the 2D image plane. Here, all the real-world points have Z coordinate as 0. Hence:\n\n\n\n\n\nWe get the Projective transformation equation as\n\n\n\n\n\nWe need 4 correspondences to constrain all 8 degrees of freedom. The elements are stored in row order In general, a Projective transformation can map any 4 points to any 4 points, with no triplets of collinear points. However, using more than 4 correspondences makes the results more robust. Stacking together all correspondences for a given time stamp we get the \\(A\\) matrix. Hence,\n\\[Ah = 0\\]\nWe perform least squares optimization by taking the SVD decomposition of matrix A.\n\n\n\n\n\nWe get the homography matrix from 9th coloumn of the V matrix.\n\n\n\n\n\nFrom this we extract our Rotation matrix \\((R)\\) and our Translation Vector \\((T)\\).\n\n\n\n\n\nThe diagonal guarantees it is a rotation matrix with determinant 1. To find our estimate of the translation we just make sure it is in the right scale using the following.\n\\[T = \\hat{T}/||\\hat{R_1}||\\]"
  },
  {
    "objectID": "posts/5_RLAN_2_VO/index.html#pose-tracking-results",
    "href": "posts/5_RLAN_2_VO/index.html#pose-tracking-results",
    "title": "Vision Based Pose and Velocity Estimation",
    "section": "Pose Tracking Results",
    "text": "Pose Tracking Results\nThe results show that the calculated pose (blue) is closely tracking the ground truth from the Vicon (red).\n\n\n\nDataset 1: Position and Orientation Tracking Results\n\n\n\n\n\nDataset 2: Position and Orientation Tracking Results"
  },
  {
    "objectID": "posts/5_RLAN_2_VO/index.html#part-ii-velocity-estimation",
    "href": "posts/5_RLAN_2_VO/index.html#part-ii-velocity-estimation",
    "title": "Vision Based Pose and Velocity Estimation",
    "section": "Part II: Velocity Estimation",
    "text": "Part II: Velocity Estimation\n\nMethodology\nWe first extract corners in each image. I used MATLAB’s built in corner detectors detectFASTfeatures to accomplish this. The extracted corners includes corners from the random scribble.\nAfter extracting corners, the next step is to compute the motion(Optical Flow) between these corners in two consecutive images. This is achieved using the Kanade-Lucas-Tomasi (KLT) feature tracker in MATLAB. Optical flow refers to the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and the scene.\nWe need to solve the Motion Field Equation for the case of fixed depth. The Motion Field Equation relates the image plane velocities of the points (denoted by \\(( \\dot{p} )\\)) to the motion of the camera or object. This equation is based on the assumption of a fixed depth (denoted by \\(( Z )\\)), where$ ( A(p) )$ and \\(( B(p) )\\) are functions of the point coordinates in the image, and \\(( V )\\) and \\(( \\Omega )\\) represent the linear and angular velocities, respectively. \\[ \\dot{p} = \\frac{1}{Z} A(p)V + B(p)\\Omega\\] \\[\\dot{p} = \\frac{1}{Z} A(p)V + B(p)\\Omega = \\left( \\frac{1}{Z} A(p) \\quad B(p) \\right) \\begin{pmatrix} V \\\\ \\Omega \\end{pmatrix}\\]\nLeast Squares Minimization: The estimated velocities are obtained by solving an optimization problem, where the sum of the squared differences between the observed image plane velocities (( _i )) and those predicted by the Motion Field Equation is minimized. This is a classic least squares problem\n\\[V^*, \\Omega^* = \\arg\\min_{V,\\Omega} \\sum_{i=1}^n \\left\\| \\left( \\frac{1}{Z_i} A(p_i) \\quad B(p_i) \\right) \\begin{pmatrix} V \\\\ \\Omega \\end{pmatrix} - \\dot{p}_i \\right\\|^2\n\\]\nVelocity Estimation Equation: Finally, the solution to the optimization problem yields the estimated linear and angular velocities \\(( V^*)\\) and \\(( \\Omega^* )\\), encapsulated in a matrix form. The matrix $ ( H^+ )$ is the pseudo-inverse of a matrix \\(( H )\\), which relates the observed velocities \\(( \\dot{p} )\\) to the motion parameters \\(( V )\\) and \\(( \\Omega )\\). The pseudo-inverse is used when the system of equations is either underdetermined or overdetermined, allowing for a least squares solution to the problem.\n\\[\\begin{pmatrix}\nV^* \\\\\n\\Omega^*\n\\end{pmatrix} = H^+ \\dot{p}\\]\n\n\nRANSAC (RANdom SAmple Consensus)\nRANSAC is an algorithm used for estimating parameters of a mathematical model from a set of data that may contain outliers. The algorithm works by iteratively selecting random subsets of data points and fitting a model to these subsets. The model parameters are then evaluated on the remaining data points, and if the model fits well to a sufficient number of points, it is considered a good fit and the algorithm terminates. The number of attempts(k) required to achieve a probability of success Psuccess is given by the equation \\[k = \\frac{\\log(1 - P_{\\text{success}})}{\\log(1 - e^{-M})}\n\\]\nTo implement RANSAC I use the following pseudocode \n\n\nVeloctiy Estimation Results\nThe graph has a noticeable pattern of increased activity, particularly spikes, which could indicate rapid changes in altitude or disturbances affecting the drone’s movement. The predictions seems to be noisy need to experiment by tuning tracker parameters and using different tracker algorithms. Overall, the predictions track the true velocities closely but there is room for improvement.\n\n\n\nLinear and Angular Velocity Estimation Results\n\n\nNext : Unscented Kalman Filter"
  },
  {
    "objectID": "posts/7_Manipulator_Kinematics/index.html",
    "href": "posts/7_Manipulator_Kinematics/index.html",
    "title": "SCARA Manipulator: Kinematic Control Part I",
    "section": "",
    "text": "This project will cover the following topics:  1. Deriving Forward kinematics using DH Parmamertization of a robotic Arm  2. Forward Differential Kinematics  3. Inverse Differential Kinematics (using Jacobian Inverse and Jacobian Transpose) 4. Exploiting redundant DOFs to add a secondary objective\nConsider the SCARA manipulator depicted below.\n\n\n\n\n\nOur Goal is to have the SCARA manipulator end effector follow the given position and velocity trajectories.\n\nThe manipulator parameteres are \\[ d_0 = 1 \\: m\\] \\[a_1 = a_2 = 0.5 \\: m\\] \\[ \\theta_{1_{min}} = - \\pi / 2 \\: rad, \\theta_{1_{max}} = \\pi / 2 \\: rad \\] \\[ \\theta_{2_{min}} = - \\pi / 2 \\: rad, \\theta_{2_{max}} =  \\pi / 4 \\: rad  \\] \\[ d_{3_{min}} = 0.25\\: m , d_{3_{max}} = 1\\: m \\] \\[ \\theta_{4_{min}} = - 2\\pi \\: rad, \\theta_{4_{max}} =  2\\pi \\: rad  \\]\nThe frames are depicted into the figure and the DH parameters are:\n\nDH Parameters\n\n\n\n\n\n\n\n\n\n\n\\(d_i\\)\n\\(\\alpha_i\\)\n\\(\\theta_i\\)\n\\(a_i\\)\n\n\n\n\nLink 1\n\\(0\\)\n\\(0\\)\n\\(\\theta_1\\)\n\\(a_1\\)\n\n\nLink 2\n\\(0\\)\n\\(0\\)\n\\(\\theta_2\\)\n\\(a_2\\)\n\n\nLink 3\n\\(d_3\\)\n\\(0\\)\n\\(0\\)\n\\(0\\)\n\n\nLink 4\n\\(0\\)\n\\(0\\)\n\\(\\theta_4\\)\n\\(0\\)\n\n\n\nwhere \\(d_i\\) and \\(\\alpha\\) are the translational and rotational offsets along the \\(x\\) axis of frame \\(i-1\\) and frame \\(i\\). \\(\\theta_i\\) and \\(a_i\\) are the joint angles and link lengths respectively.\nNote that the 0 frame is not coincident with the b frame. There is a translation from the ground plane denoted with \\(d_0 = 1\\). The frame 4 is coincident with the frame 3 at the starting. Be careful on the \\(d3\\) component. The range of values is always positive. When the arm is fully extended (down towards the floor) the value is 1m whereas 0.25 when retracted (away from the floor). However, when you build your matrix note that \\(d_3\\) moves along \\(−z_2\\) axis and for this reason you translation in \\(A_{23}\\) should be negative as \\(−d_3\\)."
  },
  {
    "objectID": "posts/7_Manipulator_Kinematics/index.html#part-1",
    "href": "posts/7_Manipulator_Kinematics/index.html#part-1",
    "title": "SCARA Manipulator: Kinematic Control Part I",
    "section": "Part 1",
    "text": "Part 1\nWe implement the algorithms for kinematic inversion with inverse and jacobian transpose along the given trajectory. Adopting the Euler integration rule with integration time 1 ms. Implement a final function visualize results for each part (joint value and error).\nThe inverse kinematics equation for the given manipulator is given by \\[ \\dot{q} = J^{-1}_a(q)(\\dot{x}_d + Ke)\\] Where ‘ is the inverse of the Jacobian. is the velocity trajectory. ’ is the error between the given trajectory and the end effector position and is the gain of the system. For the SCARA robot the Jacobian is a 4×4 matrix ( Linear velocities along x, y and z and one orientation). Since there is only one orientation component the Geometric Jacobian is equal to the Analytical Jacobian. The equation given above is modeled using the following kinematic control schematic diagram.\n\n\n\n\nSimulink Block Diagram\n\n\n\nHere the ‘From Workspace’ block is used to import time series trajectory data from the workspace. A subtract block is used to calculate the error between the required trajectory and the actual position of the end effector which is calculated using direct kinematics. The error signal is passed through a gain block. The gain is set to 1000.\nFurther, an addition block and product block is used to complete the right hand side of the equation. A discrete integrator block is used to obtain from . is the input to two functions.\n\n\nDerive the Direct Kinematics\nThe direct kinematics of the system can be represented by the equation \\[ \\mathbf{x = K(q)}\\] where \\[\\mathbf{q} =\n    \\begin{bmatrix}\n    \\theta_1 \\\\\n    \\theta_2 \\\\\n    d_3 \\\\\n    \\theta_4\n    \\end{bmatrix}\n\\] and \\(\\mathbf{K(q)}\\) is a tranformation that maps the joint space \\(\\mathbf{q}\\) to the operation space \\(\\mathbf{x}\\). We can find \\(\\mathbf{K(q)}\\) by composing all the transformations from the base frame to the end effector frame.\nThe tranformation \\(A_b^0\\) is a pure translation along \\(z_b\\) \\[ A_b^0 =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 0\\\\\n    0 & 1 & 0 & 0\\\\\n    0 & 0 & 1 & d_0\\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix},\nA_0^1 =\n    \\begin{bmatrix}\n    \\cos(\\theta_1) & -\\sin(\\theta_1) & 0 & a_1 \\cos(\\theta_1)\\\\\n    \\sin(\\theta_1) & \\cos(\\theta_1) & 0 & a_1\\sin(\\theta_1)\\\\\n    0 & 0 & 1 & 0\\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}\n\\]\n\\[ A_1^2 =\n    \\begin{bmatrix}\n    \\cos(\\theta_2) & -\\sin(\\theta_2) & 0 & a_2 \\cos(\\theta_2)\\\\\n    \\sin(\\theta_2) & \\cos(\\theta_2) & 0 & a_2\\sin(\\theta_2)\\\\\n    0 & 0 & 1 & d_0\\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}\n, A_2^3 =\n    \\begin{bmatrix}\n    1 & 0 & 0 & 0\\\\\n    0 & 1 & 0 & 0\\\\\n    0 & 0 & 1 & -d_3\\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}\n\\]\n\\[ A_3^4 =\n    \\begin{bmatrix}\n    \\cos(\\theta_4) & -\\sin(\\theta_4) & 0 & 0\\\\\n    \\sin(\\theta_4) & \\cos(\\theta_4) & 0 & 0\\\\\n    0 & 0 & 1 & 0\\\\\n    0 & 0 & 0 & 1\n    \\end{bmatrix}\n\\] \\[T_3^b = A_b^0 \\cdot A_0^1 \\cdot A_1^2 \\cdot A_2^3 \\cdot A_3^4\\]\nHence the pose of the end effector \\(\\mathbf{K(q)}\\) is given by \\[\\mathbf{K(q)} =\n        \\begin{bmatrix}\n        T_3^b(0,3) \\\\\n        T_3^b(1,3) \\\\\n        T_3^b(2,3) \\\\\n        \\theta_1 + \\theta_2 + \\theta_4\n        \\end{bmatrix}\n\\]\n\n\nFind the Jacobian of the Manipulator\nThe Jacobian which is then used to find the Inverse Jacobian of the system. Using the frames given we calculate the geometric Jacobian using the Equation.\n\n\n\nwhere \\[ p_0 = [0,0,0]^T \\] \\[ p_1 = A_0^1(0:2,4)\\] \\[ p_2= A_0^2(0:2,4) ,where \\: A_0^2 = A_1^2 \\cdot A_0^1\\] \\[ p_3= A_0^3(0:2,4) ,where \\: A_0^3 = A_2^3 \\cdot A_0^2\\] \\[ p= T_3^b(0:2,4) \\]\nand \\(Z_i\\) are the \\(Z\\) components of each of the frame \\(i\\) with respect to the base frame.\nWe find the Jacobian \\(J(q)\\) to be\n\n\n\nInverting it we get \\(J^{-1}(q)\\)\n\n\n\n\n\nResults Using Jacobian Inverse\nThe error vs time chart for the end effector positions along X, Y, Z and theta are given.\n\n\n\n\n\nUsing Jacobian Transpose\nThe inverse kinematics equation for the manipulator using Jacobian Transpose \\(J_a(q)^{T}\\) is given by \\[ \\dot{q} = J_a(q)^{T}Ke\\]\nThe tranpose of the jacobian is\n\n\n\nThis method of determining joint velocities is more computationally efficient that using the inverse. However, it has lower accuracy. Hence it is used for cases with larger error tolerance.\nThe equation given above is modeled using the following kinematic control schematic diagram.\n\n\n\n\n\nSimulink Block Diagram\n\n\n\nThe discrete integrator block is used to integrate to for every millisecond sample time. The Simout blocks are used to send the and X values to the workspace. The direct kinematics block remains the same as before.\n\n\nResults Using Jacobian Transpose\n\n\n\nFrom the results it is evident that the tracking error of the Jacobian Transpose control is 3 to 4 orders of magnitude higher than the Jacobian Inverse based Control but the runtime of the code is significantly shorter."
  },
  {
    "objectID": "posts/7_Manipulator_Kinematics/index.html#part-2",
    "href": "posts/7_Manipulator_Kinematics/index.html#part-2",
    "title": "SCARA Manipulator: Kinematic Control Part I",
    "section": "Part 2",
    "text": "Part 2\nSuppose we relax one component in the operational space, we can maximize the distance from the mechanical joint limits hence avoiding unstable regions and singularities.\nHere I implement an algorithm for kinematic inversion with Jacobian pseudo-inverse along the given trajectory maximizing in two separate cases the distance from the mechanical joint limits ( by relaxing the orientation component ϕ).\n\\[ \\dot{q} = J^+_a(\\dot{x}_d+Ke) + (I - J_a^+J_a)\\dot{q}_a\\]\nWhere \\(J^+_a\\) is the Jacobian PseudoInverse.\n\n\n\n\\(K\\) is a positive definite matrix and convergence depends on the eigen values finally the \\(q_a\\) enables us to generate internal motions and optimize for certain criteria without changing end effector position. In our case we want to stay as close as possible to the center of the joint range.\n\\[ \\dot{q_a} = k_0 \\left( \\frac{\\partial w(q)}{\\partial q} \\right)\\]\nwhere \\(k_0 > 0\\) and \\(q_a\\) is a (secondary) objective function of the joint variables.\n\\[\nw(q) = \\frac{1}{2n} \\sum_{i=1}^n \\left( \\frac{ q_i - \\bar{q_i}}{q_{iM}-q_{im}} \\right)\\]\nHere \\(w(q)\\) is a cost function that when minimized ensures that the joint positions are close to the center of its range.\\(q_{iM}\\) and \\(q_{im}\\) denotes the maximum and minimum joint limits respectively and \\(\\bar{q_i}\\) is the middle value of the joint range; thus, by maximizing this distance, redundancy is exploited to keep the joint variables as close as possible to the centre of their ranges.\n\nSimulink Block Diagram\n\n\n\nThe Simulink Network above is very similar to the previous block diagrams. However it has a few key differences.\nFirstly, the orientation term has been relaxed. Hence \\(\\theta_d\\) and \\(\\dot{\\theta_d}\\) are not input into the system.The direct kinematics block is the same as that implemented in previous questions. However, I have used a second block to relax the orientation component. In essence, converting a 4X1 matrix to a 3X1 matrix.\nSecondly I have implemented two subsystems. Subsystem one takes input \\(q\\) and returns the Jacobian \\(J\\) and the jacobian pseudo inverse \\(J^+_a\\).\n\n\n\nSub system 2 takes \\(q\\), the Jacobian and the Jacobian pseudo inverse as input and returns the term \\((I - J_a^+J_a)\\dot{q}_a\\) .\n\n\n\n\n\nPart 2 Results\nThe error vs time chart for the end effector positions along X,Y and Z axes are given."
  },
  {
    "objectID": "posts/8_Manipulator_Obstacle_Avoidance/index.html",
    "href": "posts/8_Manipulator_Obstacle_Avoidance/index.html",
    "title": "SCARA Manipulator: Kinematic Control Part II",
    "section": "",
    "text": "This project will cover the following topics:  1. Second Order inverse differential kinematics of a Scara robotic Arm  2. Obstacle Avoidance by maximizing distance between joins and an Obstacle\nConsider the SCARA manipulator depicted below.\n\n\n\n\n\nOur Goal is to have the SCARA manipulator end effector follow the given position and velocity trajectories.\n\nImplement in Matlab/Simulink a second order algorithm for kinematic inversion with jacobian inverse along the given trajectory. Adopt the Euler integration rule with integration time 1 ms.\n\n\nOur Goal is to have the SCARA manipulator end effector follow the given position and velocity trajectories.\n\nImplement in Matlab/Simulink a second order algorithm for kinematic inversion with jacobian inverse along the given trajectory. Adopt the Euler integration rule with integration time 1 ms.\n\n\n\nThe Second order inverse kinematics equation for the given manipulator is given by\n\\[ \\ddot{q} = J^{-1}_a(q)(\\ddot{x}_d + K_d\\dot{e}+K_pe-\\dot{J_a}(q,\\dot{q})\\dot{q})\\]\nWhere \\(J^{-1}_a(q)\\) is the inverse of the Jacobian. \\(\\ddot{x_d}\\) is the acceleration trajectory. \\(e\\) is the error between the given trajectory and the end effector position. \\(K_d\\) and \\(K_p\\) are gains. For the SCARA robot the Jacobian is a 4×4 matrix. Since the \\(Z\\) component of the end effector is parallel to the \\(Z\\) component of the base frame the Geometric Jacobian is equal to the Analytical Jacobian.\nThe equation given above is modeled using the following kinematic control schematic diagram.\n\n\n\n\n\n\n\n\n\nThe time series trajectory data is imported from the workspace. A subtract block is used to calculate the error between the required trajectory and the actual position of the end effector which is calculated using direct kinematics. The error signal is passed through a gain block.\n\\(J_a(q,\\dot{q})\\) is calculated by differentiating \\(J_a(q)\\) with respect to \\(t\\).\n\\[\\frac{dJ_a}{dt} =\\frac{dJ_a}{dq}∙\\frac{dq}{dt}\\]\nWe get \\(J_a(q)\\) as\n\n\n\nFinally the function “q_double_dot” is used to bring together all the terms and calculate \\[\\ddot{q} = J^{-1}_a(q)(\\ddot{x_d}+K_d\\dot{e}+K_pe-\\dot{J_a}(q,\\dot{q})\\dot{q})\\]\nHere \\(J_a^{-1}(q)\\) is found to be\n\n\n\n\\(\\ddot{q}\\) is integrated twice to get \\(q\\). The mechanical joint limits are entered in the discrete integrator block . The upper saturation limit is \\([π/2, \\: π/4, \\: 1, \\: 2π]^T\\) and the lower saturation limit is \\([−π/2, \\: −π/2, \\: 1/4, \\: −2π]^T\\).\n\n\n\nJoint space trajectories are found to be.\n\n\n\nThe error vs time chart for the end effector positions along X, Y and Θ are ."
  },
  {
    "objectID": "posts/8_Manipulator_Obstacle_Avoidance/index.html#part-2",
    "href": "posts/8_Manipulator_Obstacle_Avoidance/index.html#part-2",
    "title": "SCARA Manipulator: Kinematic Control Part II",
    "section": "Part 2",
    "text": "Part 2\nSuppose to relax one component in the operational space (relax the z component), implement in Matlab/Simulink the second order algorithm for kinematic inversion with Jacobian pseudo-inverse along the given trajectory maximizing the distance from an obstacle along the path. Suppose that the obstacle is a sphere centered in p = [0.4 −0.7 0.5]⊤ with radius 0.2 m.\n\nExploit Redundancy using Jacobian Pseudo-inverse\n\\[ \\ddot{q} = J^{+}_a(\\ddot{x}_d + K_d\\dot{e}+K_pe-\\dot{J_a}(q,\\dot{q})\\dot{q})+(I_n-J^{+}_aJ_a)\\ddot{q}_0 \\]\nWhere \\(J^{+}_a\\) is the Jacobian Pseudo inverse.\n\n\n\n\\(\\dot{q}_0\\) enables us to generate internal motions and optimize for certain criteria without changing end effector position. In our case we want to stay as close as possible to the center of the joint range.\n\\[\\dot{q}_0 = k_0 \\left( \\frac{\\partial w(q)}{\\partial q} \\right)^T\\]\nwhere \\(k_0 > 0\\) and \\(w(q)\\) is a (secondary) objective function of the joint variables.\n\\[w(q)=   _{p, o}^{min} ||p(q)−o||\\]\nHere \\(w(q)\\) is a cost function that when minimized ensures that the end distance between the effector position pq and the obstacle \\((o)\\) is maximized.\nThe distance is calculated using the equation\n\\[w(q) = \\sqrt{(p_x−o_x)^2+(p_y−o_y)^2+(p_z−o_z)^2}\\]\nSubstituting \\(p_x, p_y\\) and \\(p_z\\) \\[ \\sqrt{\\left( \\frac{cos(\\theta_1+\\theta_2)}{2} + \\frac{cos(\\theta_1)}{2}-\\frac{2}{5} \\right)^2  + \\left( \\frac{sin(\\theta_1+\\theta_2)}{2} + \\frac{sin(\\theta_1)}{2}-\\frac{7}{10} \\right)^2 +  \\left( d_3 - \\frac{1}{2} \\right) }\\]\nIntegrating twice with respect to “q” and multiply gain ‘\\(k_0\\)’ we get \\(q_0\\).\n\n\nSimulink Block Diagram\n\n\n\nThe Simulink Network above is very similar to the previous block diagrams. However it has a few key differences.\nFirstly, the ‘\\(Z\\)’ term has been relaxed. Hence it is not input into the system. The direct_kin, xe_dot and J_dot_r*q_dot block is the same as that implemented in previous model. However,the code has been altered to accommodate the relaxed Jacobian. In essence, converting a 4×1 matrix to a 3×1 matrix.\nSecondly I have implemented the subsystem “[In - J_pinv.J]*q_dd”. Subsystem one takes input ‘q’ and returns the jacobian pseudo inverse ‘J_pinv’ and an additional term In− JA†JAq0.\n\n\n\n“[In - J_pinv.J]*q_dd” Subsystem\nThe subsystem is composed of two functions. The “J_pinv” function takes as input “q” and returns the Jacobian “J” and the Jacobian pseudo-inverse “J_pinv”. The function “calc_term” returns the term \\((I_n− J_a^†J_a)\\ddot{q_0}\\)\n\n\nResults\nJoint space trajectories are found to be. Notice that q3 is constant this correlates with the lowest position of the end effector. In essence, the maximum distance from the obstacle.\nThe error vs time chart for the end effector positions along X,Y and Θ axes are given."
  }
]